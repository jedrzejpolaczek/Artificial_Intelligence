{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error Funcions\n",
    "\n",
    "There are many possible error functions we can use to achieve that adjustation. \n",
    "\n",
    "What is error function? Is something that tell us how far we are from the solution. It is a sum of all errors.\n",
    "\n",
    "## General idea\n",
    "General idea is, to sum up the error for each input and minimize this value.\n",
    "\n",
    "## Discrete error function vs Continouous error function \n",
    "If we want to sum up the output of the error function it may create value. The problem is if the error is discrete. But what does it mean? \n",
    "### Problem with descrete error values\n",
    "If we counting error value discrete, for each step we just check if changing values of weights and bias decrease the number of errors we had. In other words, a very small change (step) of weights and bias may be in the right direction but may not immediately change the number of errors we had. Also, we should remember that making big changes (steps) can be an overdose and we can just make so big changes that solve one error but will cause new errors.\n",
    "### How to solve this problem?\n",
    "We can solve this by counting error values in a continuous way. In developer language just change int to float! That will allow us to see more precisely if your change has any impact in a matter of decreasing error value. Remember, changing from an error value of 0.0002 to 0.0001 is still a change in the right direction!\n",
    "\n",
    "## How calculate error value?\n",
    "We calculate the error value as the difference between the expected output and the predicted output.\n",
    "\n",
    "For example let say we look at logical AND.\n",
    "\n",
    "For both discrete and continuous error function, we will calculate output with equation $y(x_1, x_2) = weight_1 * x_1 + weight_2 * x_2 +b$ (standard sum of all inputs multiplyed by their weights with addition of bias for artificial neuron).\n",
    "\n",
    "### For discrete error function\n",
    "We will assume the activation function will give 1 for values bigger than 0.5 and 0 for values smaller than 0.5.\n",
    "\n",
    "So expected output value ( $y$ ) for $x_1 = 0$ and $x_2 = 1$ should be $y = 0$ \n",
    "\n",
    "and lets say predicted output value based on calculation of function $y(x_1, x_2)$ will be $\\hat y = -1.25$ and passing it to activation function will give us $\\hat y = 0$\n",
    "\n",
    "So for $y = 1$ (expected output) and $\\hat y = 1$ (predicted output) error value will be $y - \\hat y = 1 - 0 = 1$. Thets mean we still have some errors but we do not know did the change of weight and bias bring us closer to finding optimal values of them.\n",
    "\n",
    "In other words discrete error function is giving us the naswer \"Yes/No\" on question \"If we have correct answer?\".\n",
    "\n",
    "### For continouous error function\n",
    "We will assume the activation function will give value between 0 and 1.\n",
    "\n",
    "So expected output value ( $y$ ) for $x_1 = 0$ and $x_2 = 1$ should be $y = 0$ \n",
    "\n",
    "and lets say predicted output value based on calculation of function $y(x_1, x_2)$ will be $\\hat y = -1.25$ and passing it to activation function will give us $\\hat y = 0.45$\n",
    "\n",
    "So for $y = 1$ (expected output) and $\\hat y = 1$ (predicted output) error value will be $y - \\hat y = 1 - 0.45 = 0.55$. So we know we are very close to find optimal values of weights and bias, beacuse error value of $0.55$ is not very small!\n",
    "\n",
    "In other words, the discrete error function is giving us the percentage value of how correct our answer is on question \"If we have the correct answer?\" (like we are correct in 55%).\n",
    "\n",
    "### Why \"predicted\" output?\n",
    "We can look at it like our neural network try to predict output (based on weights values and bias values it currently has), that's why we call it predicted output and not just output (until we finish train our neural network).\n",
    "\n",
    "## Activation function for continouous values\n",
    "One more thing worth noting is the activation function for continuous values. We can have many functions that change $y(x_1, x_2) = weight_1 * x_1 + weight_2 * x_2 +b$ in to value between 0 and 1 (they are our activation functions), for example:\n",
    "\n",
    "### Sigmoid\n",
    "To change $y(x_1, x_2)$ to output between 0 and 1 we can use sigmoid function. It's simply formula:\n",
    "\n",
    "$f(h) = \\frac{1}{1+e^{-h}}$\n",
    "\n",
    "It looks like this (image from [wiki](https://en.wikipedia.org/wiki/Sigmoid_function)):\n",
    "![title](sigmoid.png)\n",
    "\n",
    "How we can see any input is changed into values between 0 and 1, and values between 0 and 1 are very easy to show as a percentage! That is what we need!\n",
    "\n",
    "# Many classes (choose between cat, dog, pigeon and others!)\n",
    "\n",
    "Previously case was ease. We just calculate if something is or it's not (like the output of AND function) of probability how much something is (like 95% for that that you get into university and 5% you need to try again). \n",
    "\n",
    "But what if we need to choose between many classes of objects like we need to decide if an image is a dog, cat, pigeon, or something else? \n",
    "\n",
    "We need to have method that will tell us theat probability of dog is 80% for cat 10% for pigeon 5% and 5% for something else. Of course, we can use all methods and tricks we learn already like error functions and continuous values.\n",
    "\n",
    "# How find optimal solution (draw line) for non-linear regions for many class?\n",
    "We can have many factors like if thing we check have furr, tail, paws, feathers beak and so on. Based on that we can calculate some score for our input. Let say after throwing a dog, cat, and pigeon  (to a neural network which task is to identify animal) we receive results:\n",
    "* dog = 2\n",
    "* cat = 1\n",
    "* pigeon = 0\n",
    "\n",
    "Now we need to figure out how to change this value to probability. We can try to count the average:\n",
    "* dog = $\\frac{2}{2+1+0} = \\frac{2}{3}$\n",
    "* cat = $\\frac{1}{2+1+0} = \\frac{1}{3}$\n",
    "* pigeon = $\\frac{0}{2+1+0} = 0$\n",
    "Sounds good but what if your score were like this:\n",
    "* dog = 1\n",
    "* cat = 0\n",
    "* pigeon = -1\n",
    "In that case, the average will looks like:\n",
    "* dog = $\\frac{1}{1+0-1} = \\frac{1}{0}$\n",
    "* cat = $\\frac{0}{1+0-1} = \\frac{0}{0}$\n",
    "* pigeon = $\\frac{-1}{1+0-1} = \\frac{-1}{0}$\n",
    "and this is terribly wrong! We can not divide by 0! \n",
    "\n",
    "So we can see this approach restricts us to only positive values, and it may be quite troublesome, also average may give us values bigger than one. So dead end? No. this is not our solution but the direction was good. We need to figure out a function that will always give us values between 0 and 1 regardless of input.\n",
    "\n",
    "First step is to make sure we always have positive output. To do it we will use exponential function.\n",
    "Ok so if we adjust it to our first example we will get:\n",
    "* dog = $\\frac{e^2}{e^2+e^1+e^0} = 0.67$\n",
    "* cat = $\\frac{e^1}{e^2+e^1+e^0} = 0.24$\n",
    "* pigeon = $\\frac{e^0}{e^2+e^1+e^0} = 0.09$\n",
    "and worth to mention $0.67 + 0.24 + 0.09 = 1$ so we can interpret it as percentage valu!\n",
    "We can also generalize it and get...\n",
    "\n",
    "### Softmax\n",
    "$P(class i) = \\frac{e^{h_i}}{\\sum_{i=1}^n e^{h_1}+...+e^{h_n}}$\n",
    "where $h_1,..., h_n$ are linear function scores (in other words $\\sum_{i=0}^n Wx + bias$).\n",
    "\n",
    "How we can see any input is changed into values between 0 and 1, and values between 0 and 1 are very easy to show as a percentage! That is what we need!\n",
    "\n",
    "### Sigmoid vs Softmax\n",
    "Quick reminder.\n",
    "\n",
    "Sigmoid $f(h_i) = \\frac{1}{1+e^{-h_i}}$, softmax $P(class_i) = \\frac{e^{h_i}}{\\sum_{i=1}^n e^{h_1}+...+e^{h_n}}$\n",
    "\n",
    "\n",
    "\n",
    "To see the difference let implement both.\n",
    "\n",
    "## Implementation of softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sigmoid 0.11920292202211755, Softmax 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(value):\n",
    "    return 1/(1+np.exp(value))\n",
    "\n",
    "def softmax_1(list_of_values):\n",
    "    exp_fom_list_of_values = np.exp(list_of_values)\n",
    "    sum_of_exp_fom_list_of_values = sum(exp_fom_list_of_values)\n",
    "    result = []\n",
    "    for i in exp_fom_list_of_values:\n",
    "        result.append(i*1.0/sum_of_exp_fom_list_of_values)\n",
    "    return result\n",
    "\n",
    "def softmax_2(list_of_values):\n",
    "        exp_fom_list_of_values = np.exp(list_of_values)\n",
    "        return np.divide (exp_fom_list_of_values, exp_fom_list_of_values.sum())\n",
    "\n",
    "print(\"Sigmoid {}, Softmax {}\".format(sigmoid(2), softmax_2([2])[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-Hot Encoding \n",
    "### aka casting numbers into classes!\n",
    "Ok so now we know how to turn input values into output numbers (like percentage). Ok but how turn it into classes?\n",
    "Simple, just create a table where you cast your output value into classes. Example, from:\n",
    "* Animal = Dog\n",
    "* Value = ???\n",
    "\n",
    "cast it into:\n",
    "* Animal = Dog\n",
    "* Dog? = 1\n",
    "* Cat? = 0\n",
    "* Pigeon? = 0\n",
    "\n",
    "and that's it!\n",
    "\n",
    "Ok so if we know how our new Softmax activation function works, how we use the error function here? Should we sum all probabilities? Well actually...\n",
    "\n",
    "## Maximum Likelihood \n",
    "### aka step before error function for Neural networks with Softmax activation function!\n",
    "Before we go into the error function let see on example. It is a very simple chart with two red and two blue dots. Let's divide it in two ways:\n",
    "![title](wrong.png)![title](right.png)\n",
    "Ok we clearly see that in second weight and bias are better adjusted so for learning purposes let's concentrate on the first one:\n",
    "![title](wrong.png)\n",
    "### How to calculate predicted output?\n",
    "Simply, we will use the *sigmoid* function to calculate predicted probability for a certain point.\n",
    "\n",
    "$\\hat y_j = \\sigma(\\sum_iW_jix_i + b_i)$\n",
    "\n",
    "In our example we will count the predicted probability for being blue:\n",
    "\n",
    "$P(blue) = \\sigma(Wx + b)$\n",
    "\n",
    "so we will get:\n",
    "![title](wrong_prob.png)\n",
    "Remember, in this example we only simulate calculations, but normally we need to first calculate $X = Wx + b$ and after that $\\sigma(x)$.\n",
    "\n",
    "Ok so now we can see that the probability of dots being blue in area outlined in blue is higher to be blue then red.\n",
    "\n",
    "We can calculate probabilities of being red by the subtracted probability of being blue from 1: $P(red) = 1 - P(blue)$ (from the definition of probability). \n",
    "\n",
    "#### Where is error value?\n",
    "Here! Error value is: $y-\\hat y$. We can say that our $y$ is a probability of 100% that dot is of some color. From that, we can say that error value is predicted output. But hey, stop! In our example it will work for blue dots but what with red dots? Easy peasy lemon squeezy! Just subtract the probability of being blue from 100% and you will get the probability of being red aka your error value for red dots!\n",
    "\n",
    "#### Let's continue\n",
    "So we get:\n",
    "![title](wrong_prob_all.png)\n",
    "\n",
    "Ok, we are almost there! If we know witch dot has which color (your expected output) we can concentrate only on the probability of dot being in his right color. So we get:\n",
    "![title](wrong_prob_red_and_blue.png)\n",
    "\n",
    "#### Calculating the probability for whole set\n",
    "Ok so now we know the probabilities for each dot. It is allowing us to calculate the probability of being accurate for the whole set. It will be a prodcut of the probabilities of all points:\n",
    "\n",
    "$P(red) x P(red) x P(blue) x P(blue) = 0.1 x 0.7 x 0.6 x 0.2 = 0.0084$\n",
    "\n",
    "It gives us less than 1%. What those it mean? That the probability of our neural network guessing the correct color is less than 1%. \n",
    "\n",
    "Let's see how it works for second graph:\n",
    "![title](right_prob.png)\n",
    "So we can read from the graph the probability of the whole set will be:\n",
    "\n",
    "$P(red) x P(red) x P(blue) x P(blue) = 0.6 x 0.8 x 0.7 x 0.9 = 0.3024$\n",
    "\n",
    "It gives us more than 30% of the probability of our neural network guessing the correct color!\n",
    "\n",
    "#### How get maximum likelihood?\n",
    "Just adjust weights and bias (using tools like change ratio and error function) until the probability will be highest from them all!\n",
    "\n",
    "But wait... how we will know that probability is the highest? So we can...\n",
    "\n",
    "## Cross-Entropy\n",
    "$-{\\sum_{i=1}^m y_i ln(p_i) + (1 - y_i)ln(1 - p_i)}$\n",
    "### aka counting error function for whole set\n",
    "Ok, so in the previous example, we just sum up error function products for the whole set and tried to decrease it. Now we create a product of error values. It will take a lot of computing time but we may still use the product of each probability. (note: sum take much less computing time). Ok, so how to turn product into sum? By using the logarithm function! Why? Because:\n",
    "\n",
    "$log(ab) = log(a) + log(b)$\n",
    "\n",
    "So for our red/blue dots example it will be:\n",
    "* bad one (product: 0.0084): $ln(0.1 x 0.7 x 0.6 x 0.2) = ln(0.1) + ln(0.7) + ln(0.6) + ln(0.2) = -2.3 - 0.36 - 0.51 - 1.61 = -4.8$\n",
    "* good one (product: 0.3024): $ln(0.6 x 0.8 x 0.7 x 0.9) = ln(0.6) + ln(0.8) + ln(0.7) + ln(0.9) = -0.51 - 0.22 - 0.36 - 0.1 = -1.2$\n",
    "\n",
    "Woah, STOP! All negative numbers? Well, let's fix it by using a negative logarithm!\n",
    "* bad one (product: 0.0084): $-ln(0.1 x 0.7 x 0.6 x 0.2) = -ln(0.1) - ln(0.7) - ln(0.6) - ln(0.2) = 2.3 + 0.36 + 0.51 + 1.61 = 4.8$\n",
    "* good one (product: 0.3024): $-ln(0.6 x 0.8 x 0.7 x 0.9) = -ln(0.6) - ln(0.8) - ln(0.7) - ln(0.9) = 0.51 + 0.22 + 0.36 + 0.1 = 1.2$\n",
    "\n",
    "#### So where is our Cross-Entropy\n",
    "Here! The Sum of negatives of logarithms of the probabilities is the cross-entropy! It's quite important later so remember it, shall we?\n",
    "\n",
    "So how we can see, the lower the number the better! Higher probability comes with lower cross-entropy!\n",
    "\n",
    "We can see it in the picture:\n",
    "![title](wrong_entropy.png)\n",
    "![title](right_entropy.png)\n",
    "Correct classification gives us lower negative logarithm (entropy) value. We can also treat $-log(x)$ as error function!\n",
    "\n",
    "#### Cross-entropy is our error function for continuous output values read as probability!\n",
    "\n",
    "### Getting to the Cross Entropy formula\n",
    "#### aka getting to error function formula\n",
    "Cuz's realization of our error function will be cross-entropy!\n",
    "\n",
    "### Introduce new example\n",
    "Let's try to find in witch house is a dog. We know probabilities for each of the three houses.\n",
    "* Red house:   $P_1(dog) = 0.8, P_1(not dog) = 0.2$\n",
    "* Blue house:  $P_2(dog) = 0.7, P_2(not dog) = 0.3$\n",
    "* Green house: $P_3(dog) = 0.1, P_3(not dog) = 0.9$\n",
    "Like in the previous example we can make a product of probabilities to count how high effectiveness has our neural network (or to count error value). But which probabilities choose? That one they are more like to happen! So for the red house is more likely to have a dog so we take that value (0.8), for the blue one also (0.7), and for the green house more likely is to not have a dog so we take it (0.9). So our product will be:\n",
    "\n",
    "$0.8 x 0.7 x (1-0.1) = 0.504$\n",
    "\n",
    "It's 50%! Just for notice: why $P_3 = 1-0.1$? Because the probability of something not happen is 100% minus the probability that something happens.\n",
    "Ok but 50% it's quite high like... flipping the coin. Maybe other products have a higher value? Let's check:\n",
    "* $P_1(dog)     x P_2(dog)     x P_3(dog)    $ ; Probability: $0.8       x 0.7       x 0.1       = 0.056$ ;\n",
    "* $P_1(dog)     x P_2(dog)     x P_3(not dog)$ ; Probability: $0.8       x 0.7       x (1 - 0.1) = 0.504$ ;\n",
    "* $P_1(dog)     x P_2(not dog) x P_3(dog)    $ ; Probability: $0.8       x (1 - 0.3) x 0.1       = 0.024$ ;\n",
    "* $P_1(not dog) x P_2(dog)     x P_3(dog)    $ ; Probability: $(1 - 0.8) x 0.7       x 0.1       = 0.014$ ;\n",
    "* $P_1(dog)     x P_2(not dog) x P_3(not dog)$ ; Probability: $0.8       x (1 - 0.3) x (1 - 0.1) = 0.216$ ;\n",
    "* $P_1(not dog) x P_2(dog)     x P_3(not dog)$ ; Probability: $(1 - 0.8) x 0.7       x (1 - 0.1) = 0.126$ ;\n",
    "* $P_1(not dog) x P_2(not dog) x P_3(dog)    $ ; Probability: $(1 - 0.8) x (1 - 0.3) x 0.1       = 0.006$ ;\n",
    "* $P_1(not dog) x P_2(not dog) x P_3(not dog)$ ; Probability: $(1 - 0.8) x (1 - 0.3) x (1 - 0.1) = 0.054$ ;\n",
    "\n",
    "Ok, so we now know which is the highest probability and it is a little bit more than 50%. But let's use what we learned previously. Let's count negative logarithm from probability:\n",
    "* $P_1(dog)     x P_2(dog)     x P_3(dog)    $ ; Probability: $0.8       x 0.7       x 0.1       = 0.056$ ; -ln(Probability): $2.88$\n",
    "* $P_1(dog)     x P_2(dog)     x P_3(not dog)$ ; Probability: $0.8       x 0.7       x (1 - 0.1) = 0.504$ ; -ln(Probability): $0.69$\n",
    "* $P_1(dog)     x P_2(not dog) x P_3(dog)    $ ; Probability: $0.8       x (1 - 0.3) x 0.1       = 0.024$ ; -ln(Probability): $3.73$\n",
    "* $P_1(not dog) x P_2(dog)     x P_3(dog)    $ ; Probability: $(1 - 0.8) x 0.7       x 0.1       = 0.014$ ; -ln(Probability): $4.27$\n",
    "* $P_1(dog)     x P_2(not dog) x P_3(not dog)$ ; Probability: $0.8       x (1 - 0.3) x (1 - 0.1) = 0.216$ ; -ln(Probability): $1.53$\n",
    "* $P_1(not dog) x P_2(dog)     x P_3(not dog)$ ; Probability: $(1 - 0.8) x 0.7       x (1 - 0.1) = 0.126$ ; -ln(Probability): $2.07$\n",
    "* $P_1(not dog) x P_2(not dog) x P_3(dog)    $ ; Probability: $(1 - 0.8) x (1 - 0.3) x 0.1       = 0.006$ ; -ln(Probability): $5.12$\n",
    "* $P_1(not dog) x P_2(not dog) x P_3(not dog)$ ; Probability: $(1 - 0.8) x (1 - 0.3) x (1 - 0.1) = 0.054$ ; -ln(Probability): $2.92$\n",
    "\n",
    "How we can predict, high probability gives us low entropy and low probability give high entropy. \n",
    "Quick reminder: $-ln(Probability) = -ln(P_1(dog/not dog)) + -ln(P_2(dog/not dog)) + -ln(P_3(dog/not dog))$\n",
    "\n",
    "Ok now we are sure we select our case correctly so we now consider it:\n",
    "* $P_1(dog) = 0.8$\n",
    "* $P_2(dog) = 0.7$\n",
    "* $P_3(not dog) = 1 - 0.1$\n",
    "* Probability: $0.8 x 0.7 x (1 - 0.1) = 0.504$\n",
    "* -ln(Probability): $0.69$\n",
    "Let's also get $y_i$ and it will be our set of expected values, 0 if the dog is not the house and 1 if the dog is in the house. For our example it will be * $y_i : (y_1 = 1, y_2 = 1, y_3 = 0)$ so we get data:\n",
    "* $P_1(dog) = 0.8$\n",
    "* $P_2(dog) = 0.7$\n",
    "* $P_3(not dog) = 1 - 0.1$\n",
    "* Probability: $0.8 x 0.7 x (1 - 0.1) = 0.504$\n",
    "* -ln(Probability): $0.69$\n",
    "* $y_i : (y_1 = 1, y_2 = 1, y_3 = 0)$\n",
    "\n",
    "### Time to Cross-Entropy formula!\n",
    "Based on our example we can get that the Cross-Entropy formula should look like this:\n",
    "\n",
    "Cross-Entropy = $-{\\sum_{i=1}^m y_i ln(p_i) + (1 - y_i)ln(1 - p_i)}$\n",
    "\n",
    "Below example of implementation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def cross_entropy(Y, P):\n",
    "    Y = np.float_(Y)\n",
    "    P = np.float_(P)\n",
    "    return -np.sum(Y * np.log(P) + (1 - Y) * np.log(1 - P))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Class Cross-Entropy\n",
    "$-\\frac{1}{m}{\\sum_{i=1}^n{\\sum_{j=1}^m y_{ij} ln(\\hat y_{ij})}}$\n",
    "\n",
    "In the previous example, we were guessing if in the house is or is not a dog. What if we want to guess if in the house is dog, cat, or pigeon? Cross-entropy we know from the previous example may not work, we need to use its variation, the multi-class cross-entropy!\n",
    "\n",
    "Let's see how our probabilities look like:\n",
    "* Red house:   $P_1(dog) = 0.7, P_2(cat) = 0.2, P_3(pigeon) = 0.1$\n",
    "* Blue house:  $P_1(dog) = 0.3, P_2(cat) = 0.4, P_3(pigeon) = 0.3$\n",
    "* Green house: $P_1(dog) = 0.1, P_2(cat) = 0.5, P_3(pigeon) = 0.4$\n",
    "\n",
    "Notice: each $P_i$ sum up for every animal need to give 1, example: $P_1(dog) + P_2(cat) + P_3(pigeon) = 0.7 + 0.2 + 0.1 = 1$. In other words sum of probabilities for each house need to be equal to 1.\n",
    "\n",
    "If we create the predicted output set like $y = (dog, pigeon, pigeon)$ we can sum it up:\n",
    "* predicted output $y = (dog, pigeon, pigeon)$\n",
    "* Probability product = $P_1(dog) x P_2(pigeon) x P_3(pigeon) = 0.7 x 0.3 x 0.4 = 0.084$\n",
    "* Cross-Entropy = $-ln(0.7) + -ln(0.3) + -ln(0.4) = 2.48$\n",
    "\n",
    "Ok, it starts to be a little bit messy. Let's clean it up and start by giving our houses numbers:\n",
    "* Red house will have number 1.\n",
    "* Blue house will have number 2.\n",
    "* Green house will have number 3.\n",
    "\n",
    "Next let's rename our probabilities:\n",
    "* House 1 (red):   $P_{11}(dog) = 0.7, P_{12}(cat) = 0.2, P_{13}(pigeon) = 0.1$\n",
    "* House 2 (blue):  $P_{21}(dog) = 0.3, P_{22}(cat) = 0.4, P_{23}(pigeon) = 0.3$\n",
    "* House 3 (green): $P_{31}(dog) = 0.1, P_{32}(cat) = 0.5, P_{33}(pigeon) = 0.4$\n",
    "\n",
    "Next step, clean expected output set:\n",
    "* $y_{1j}$ if dog is in house j (where j is between 1 and 3).\n",
    "* $y_{2j}$ if cat is in house j (where j is between 1 and 3).\n",
    "* $y_{3j}$ if pigeon is in house j (where j is between 1 and 3).\n",
    "\n",
    "Sum it up and we will get formula for multi-class cross-entropy:\n",
    "\n",
    "Multi-Class Cross-Entropy = $-{\\sum_{i=1}^n{\\sum_{j=1}^m y_{ij} ln(p_{ij})}}$\n",
    "\n",
    "Here *m* is number of classes so we want to get average from that so we will get:\n",
    "\n",
    "$-\\frac{1}{m}{\\sum_{i=1}^n{\\sum_{j=1}^m y_{ij} ln(p_{ij})}}$\n",
    "\n",
    "And of course our $p_{ij}$ is our predicted output $\\hat y_{ij}$ so we will get:\n",
    "\n",
    "$-\\frac{1}{m}{\\sum_{i=1}^n{\\sum_{j=1}^m y_{ij} ln(\\hat y_{ij})}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data]",
   "language": "python",
   "name": "conda-env-data-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
